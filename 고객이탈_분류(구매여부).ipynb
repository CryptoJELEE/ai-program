{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CryptoJELEE/ai-program/blob/main/%EA%B3%A0%EA%B0%9D%EC%9D%B4%ED%83%88_%EB%B6%84%EB%A5%98(%EA%B5%AC%EB%A7%A4%EC%97%AC%EB%B6%80).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8s_w2ZNfK0y",
        "outputId": "05a6ec5a-e6e8-42d3-c739-a76f85cfd8a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drinve\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drinve')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your_token' with your actual GitHub personal access token\n",
        "# Replace 'username' with your GitHub username\n",
        "# Replace 'repository' with the name of the repository you want to clone\n",
        "\n",
        "import os\n",
        "\n",
        "# Storing the token in an environment variable (optional)\n",
        "os.environ['GITHUB_TOKEN'] = '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'\n",
        "\n",
        "# Using the token in the git clone command\n",
        "!git clone https://github.com/CryptoJELEE/AI_python.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UziX_Bx1_X2",
        "outputId": "8b1f1332-d0d0-4155-eb26-b80a225310a5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI_python'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R268WRfbEwJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/CryptoJELEE/AI_python.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDW6nEmM1KM-",
        "outputId": "451fbd12-ba71-42c3-8aa3-2309ded542ea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI_python'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSZ4girQ0K2q",
        "outputId": "38bfecce-d7ec-499e-b7c4-f12350120b5b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filter.lfs.smudge=git-lfs smudge -- %f\n",
            "filter.lfs.process=git-lfs filter-process\n",
            "filter.lfs.required=true\n",
            "filter.lfs.clean=git-lfs clean -- %f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"Jerry\""
      ],
      "metadata": {
        "id": "OLJ3zeK70cOp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"sri930409@gmail.com\""
      ],
      "metadata": {
        "id": "5BPLgp-N0j7F"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add AI https://github.com/CryptoJELEE/AI_python.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d0d1EJn0seJ",
        "outputId": "8bc0facd-61d4-400b-d4be-a7b9b95cfd6a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMODcm42oYZu"
      },
      "source": [
        "모델 호출\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecPOhmEIhlyH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzaotBivoV2n"
      },
      "source": [
        "테이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsuR6oYuhl7v"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    ecommerce_data = pd.read_csv('/content/drinve/MyDrive/코딩/rawdata/dbdata_extract_20240513.csv')\n",
        "    ecommerce_new = pd.read_csv('/content/drinve/MyDrive/코딩/rawdata/dbdata_extract_20240513_2.csv')\n",
        "    return ecommerce_data, ecommerce_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ywNdAYqob7y"
      },
      "source": [
        "전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGMEAD_chmAz"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(ecommerce_data):\n",
        "    ecommerce_buy_y = ecommerce_data[ecommerce_data['구매여부'] == 1]\n",
        "    ecommerce_buy_nt = ecommerce_data[ecommerce_data['구매여부'] == 0]\n",
        "    max_buy_count = len(ecommerce_buy_y)\n",
        "    ecommerce_buy_n = ecommerce_buy_nt.sample(n=max_buy_count*2, random_state=42)\n",
        "    ecommerce_buy = pd.concat([ecommerce_buy_y, ecommerce_buy_n])\n",
        "    ecommerce_member = ecommerce_buy.sample(frac=1, random_state=42)  # Shuffle\n",
        "    return ecommerce_member"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHYYbkHuoe-7"
      },
      "source": [
        "피처 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8MwJupRoel2"
      },
      "outputs": [],
      "source": [
        "def feature_selection(data):\n",
        "    X = data[['방문시간', '유입출처구분', '페이지뷰', '체류시간', '이동경로', '재방문여부']]\n",
        "    y = data['구매여부']\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ekl8ogIov9t"
      },
      "source": [
        "데이터 스플릿"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVDynZm4o0Bh"
      },
      "outputs": [],
      "source": [
        "def train_test_splitting(X, y):\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMkoYHRdpW1Q"
      },
      "source": [
        "데이터 불균형 해소\n",
        "\n",
        "---\n",
        "SMOTE의 동작 방식은 데이터의 개수가 적은 클래스의 표본을 가져온 뒤 임의의 값을 추가하여 새로운 샘플을 만들어 데이터에 추가하는 오버샘플링 방식이다.\n",
        "\n",
        "https://john-analyst.medium.com/smote%EB%A1%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%88%EA%B7%A0%ED%98%95-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0-5ab674ef0b32\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cc_RBKUapbmw"
      },
      "outputs": [],
      "source": [
        "def handle_imbalance(X_train, y_train):\n",
        "    smote = SMOTE(random_state=42)\n",
        "    return smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqNkBXH1rr_9"
      },
      "source": [
        "스케일링하기\n",
        "\n",
        "훈련, 테스트테이터 세트 스케일링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pemTO_8arqba"
      },
      "outputs": [],
      "source": [
        "def scale_features(X_train, X_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    return X_train, X_test, scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx55SRzlur_8"
      },
      "source": [
        "분석 모델 설정\n",
        "\n",
        "1. 로지스틱 회귀 (Logistic Regression)\n",
        "설명: 로지스틱 회귀는 이진 분류 문제에서 많이 사용되는 선형 모델입니다. 입력된 특징들의 가중합을 로지스틱 함수에 통과시켜 두 클래스 중 하나에 속할 확률을 예측합니다.\n",
        "\n",
        "사용 경우: 이진 분류 문제, 확률 예측이 필요한 경우.\n",
        "2. 의사결정 나무 (Decision Tree)\n",
        "설명: 의사결정 나무는 데이터의 특징들에 따라 데이터를 분할하여 예측을 수행하는 트리 구조의 모델입니다. 트리의 각 노드는 특정 특징에 대한 분기 기준을 나타냅니다.\n",
        "\n",
        "사용 경우: 데이터의 특징에 따라 명확한 분류 기준이 있는 경우.\n",
        "3. 랜덤 포레스트 (Random Forest)\n",
        "설명: 랜덤 포레스트는 여러 개의 의사결정 나무를 앙상블하여 예측의 정확성을 높이는 모델입니다. 각 나무는 무작위로 선택된 데이터와 특징을 사용하여 학습됩니다.\n",
        "\n",
        "사용 경우: 과적합을 줄이고 예측의 정확성을 높이고 싶은 경우.\n",
        "4. SVM (서포트 벡터 머신, Support Vector Machine)\n",
        "설명: SVM은 데이터를 고차원 공간으로 매핑하여 두 클래스 간의 최대 마진을 찾는 분류 모델입니다. 비선형 분류를 위해 커널 트릭을 사용할 수 있습니다.\n",
        "사용 경우: 고차원 데이터, 비선형 분류 문제.\n",
        "\n",
        "5. k-NN (k-최근접 이웃, k-Nearest Neighbors)\n",
        "설명: k-NN은 새로운 데이터 포인트를 예측할 때, 가장 가까운 k개의 이웃 데이터를 참고하여 다수결로 분류를 수행하는 비모수 모델입니다.\n",
        "사용 경우: 단순한 분류 문제, 데이터의 분포를 파악하고 싶은 경우.\n",
        "\n",
        "6. 나이브 베이즈 (Naive Bayes)\n",
        "설명: 나이브 베이즈는 특징들이 서로 독립이라는 가정 하에 베이즈 정리를 적용하여 분류를 수행하는 모델입니다. 주로 텍스트 분류에 많이 사용됩니다.\n",
        "사용 경우: 텍스트 분류, 스팸 필터링.\n",
        "\n",
        "7. 신경망 (Neural Network)\n",
        "설명: 신경망은 입력층, 은닉층, 출력층으로 구성된 노드들의 네트워크입니다. 각 노드는 가중치를 가지며 활성화 함수를 통해 신호를 전달합니다. 복잡한 비선형 관계를 학습할 수 있습니다.\n",
        "사용 경우: 이미지 인식, 자연어 처리 등 복잡한 패턴 인식 문제.\n",
        "\n",
        "8. XGBoost (Extreme Gradient Boosting)\n",
        "설명: XGBoost는 그래디언트 부스팅 알고리즘을 기반으로 한 강력한 앙상블 모델입니다. 여러 약한 학습기(주로 의사결정 나무)를 순차적으로 학습시키며, 각 단계에서 이전 단계의 오차를 줄이는 방향으로 모델을 개선합니다.\n",
        "사용 경우: 대규모 데이터셋, 높은 예측 성능이 필요한 경우."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BWGmXYKuupv"
      },
      "outputs": [],
      "source": [
        "def train_models(X_train, y_train):\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(random_state=42),\n",
        "        'Decision Tree': GridSearchCV(DecisionTreeClassifier(random_state=42), {\n",
        "            'max_depth': [None, 10, 20, 30],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }, cv=5, n_jobs=-1, verbose=2),\n",
        "        'Random Forest': GridSearchCV(RandomForestClassifier(random_state=42), {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [None, 10, 20, 30],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }, cv=5, n_jobs=-1, verbose=2),\n",
        "\n",
        "        'k-NN': GridSearchCV(KNeighborsClassifier(), {\n",
        "            'n_neighbors': [3, 5, 7, 9],\n",
        "            'weights': ['uniform', 'distance']\n",
        "        }, cv=5, n_jobs=-1, verbose=2),\n",
        "        'Naive Bayes': GaussianNB(),\n",
        "        'Neural Network': GridSearchCV(MLPClassifier(random_state=42), {\n",
        "            'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
        "            'activation': ['tanh', 'relu'],\n",
        "            'solver': ['sgd', 'adam'],\n",
        "            'alpha': [0.0001, 0.05],\n",
        "            'learning_rate': ['constant', 'adaptive'],\n",
        "        }, cv=5, n_jobs=-1, verbose=2),\n",
        "        'XGBoost': GridSearchCV(xgb.XGBClassifier(random_state=42, use_label_encoder=False, tree_method='gpu_hist'), {\n",
        "            'n_estimators': [100, 200, 300],\n",
        "            'max_depth': [3, 5, 7],\n",
        "            'learning_rate': [0.01, 0.1, 0.2],\n",
        "            'subsample': [0.8, 0.9, 1.0]\n",
        "        }, cv=5, n_jobs=-1, verbose=2)\n",
        "    }\n",
        "\n",
        "    best_models = {}\n",
        "    train_times = {}\n",
        "    for name, model in models.items():\n",
        "        print(f'Training {name}...')\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train, y_train)\n",
        "        end_time = time.time()\n",
        "        train_times[name] = end_time - start_time\n",
        "        if hasattr(model, 'best_estimator_'):\n",
        "            best_models[name] = model.best_estimator_\n",
        "        else:\n",
        "            best_models[name] = model\n",
        "\n",
        "    return best_models, train_times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrWCvPVxvT43"
      },
      "source": [
        "평가하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yBg9F2svUOE"
      },
      "outputs": [],
      "source": [
        "def evaluate_models(models, X_test, y_test):\n",
        "    results = {}\n",
        "    eval_times = {}\n",
        "    for name, model in models.items():\n",
        "        start_time = time.time()\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "        end_time = time.time()\n",
        "        eval_times[name] = end_time - start_time\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        class_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
        "\n",
        "        results[name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'conf_matrix': conf_matrix,\n",
        "            'class_report': class_report,\n",
        "            'roc_auc': roc_auc\n",
        "        }\n",
        "\n",
        "    return results, eval_times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRpBVPQSvjEt"
      },
      "source": [
        "시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "iEIzJM-svmrU",
        "outputId": "3e689061-78cf-416f-b2ad-95649b65f861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "Training Random Forest...\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4dc383c5bf52>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Train and evaluate models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-38e6b3450462>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training {name}...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mtrain_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def plot_results(results, train_times, eval_times):\n",
        "    accuracies = [res['accuracy'] for res in results.values()]\n",
        "    roc_aucs = [res['roc_auc'] for res in results.values() if res['roc_auc'] is not None]\n",
        "    names = list(results.keys())\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    sns.barplot(x=accuracies, y=names)\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Accuracy')\n",
        "    plt.ylabel('Model')\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    sns.barplot(x=roc_aucs, y=names[:len(roc_aucs)])\n",
        "    plt.title('Model ROC-AUC')\n",
        "    plt.xlabel('ROC-AUC')\n",
        "    plt.ylabel('Model')\n",
        "\n",
        "    train_times_sorted = sorted(train_times.items(), key=lambda item: item[1], reverse=True)\n",
        "    eval_times_sorted = sorted(eval_times.items(), key=lambda item: item[1], reverse=True)\n",
        "    train_names, train_values = zip(*train_times_sorted)\n",
        "    eval_names, eval_values = zip(*eval_times_sorted)\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    sns.barplot(x=train_values, y=train_names)\n",
        "    plt.title('Model Training Time')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Model')\n",
        "\n",
        "    plt.subplot(2, 2, 4)\n",
        "    sns.barplot(x=eval_values, y=eval_names)\n",
        "    plt.title('Model Evaluation Time')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Model')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def display_results(results):\n",
        "    for model, metrics in results.items():\n",
        "        print(f\"Model: {model}\")\n",
        "        print(f\"Accuracy: {metrics['accuracy']}\")\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(metrics['conf_matrix'])\n",
        "        print(\"Classification Report:\")\n",
        "        print(pd.DataFrame(metrics['class_report']).transpose())\n",
        "        if metrics['roc_auc'] is not None:\n",
        "            print(f\"ROC-AUC: {metrics['roc_auc']}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    ecommerce_data, ecommerce_new = load_data()\n",
        "    ecommerce_member = preprocess_data(ecommerce_data)\n",
        "\n",
        "    # Feature selection and data splitting\n",
        "    X, y = feature_selection(ecommerce_member)\n",
        "    X_train, X_test, y_train, y_test = train_test_splitting(X, y)\n",
        "\n",
        "    # Handle class imbalance and scale features\n",
        "    X_train, y_train = handle_imbalance(X_train, y_train)\n",
        "    X_train, X_test, scaler = scale_features(X_train, X_test)\n",
        "\n",
        "    # Train and evaluate models\n",
        "    models, train_times = train_models(X_train, y_train)\n",
        "    results, eval_times = evaluate_models(models, X_test, y_test)\n",
        "\n",
        "    # Plot results\n",
        "    plot_results(results, train_times, eval_times)\n",
        "\n",
        "    # Display detailed results\n",
        "    display_results(results)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEFHf+hTS/EXBj17xw6wVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}